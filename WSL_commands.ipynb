{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7a5dfb-9606-4761-8575-676e6ac3885b",
   "metadata": {},
   "source": [
    "I executed the command lines below on WSL (Windows Subsystem for Linux) because I have a Dell laptop. For this project, I created a conda environment named JK_tophat and installed neccesary tools. To install conda (and Jupyter Notebook so you can save your code), ask chatGPT for help. To execute each code box, hit Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37010200-0373-466c-b657-897dcff879ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because tophat (read alignment tool) requires python version <3\n",
    "conda create -n JK_tophat python=2.7\n",
    "conda activate JK_tophat # now you change your environment from (base) to (JK_tophat)\n",
    "conda install samtools=1.2 bowtie2=2.2.5 tophat=2.0.14 cufflinks=2.2.1\n",
    "# to double check tools are installed\n",
    "samtools --version && echo && bowtie2 --version && echo && tophat --version echo && cufflinks --version\n",
    "# navigate to your folder/directory\n",
    "cd /mnt/c/Users/lammu/OneDrive/Desktop/your_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348a8b33-dd1a-4e79-8e20-99b1488fdb46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                   /home/lam/miniconda3\n",
      "JK                     /home/lam/miniconda3/envs/JK\n",
      "JK_tophat            * /home/lam/miniconda3/envs/JK_tophat\n",
      "centrifuge             /home/lam/miniconda3/envs/centrifuge\n",
      "kb                     /home/lam/miniconda3/envs/kb\n",
      "rnaseq                 /home/lam/miniconda3/envs/rnaseq\n",
      "rnaseq_py38            /home/lam/miniconda3/envs/rnaseq_py38\n",
      "sourmash               /home/lam/miniconda3/envs/sourmash\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This step is only neccesary for me (executing WSL commands from Jupyter Bash Notebook)\n",
    "source ~/miniconda3/etc/profile.d/conda.sh\n",
    "conda activate JK_tophat\n",
    "# To check that JK_tophat is activated\n",
    "conda info --envs # this lists all conda environments I've created\n",
    "# I should see a * in the line of JK_tophat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61590e-e522-4c1f-8726-7be592ff13ab",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "Determine genes that are differentially expressed at different stages in the development of Arabidopsis thaliana shoot apical meristem. You collected samples at day 8 and day 16 (files “Day8.fastq” and “Day16.fastq”).\n",
    "\n",
    "The reference genome is “athal_chr.fa” and the reference gene annotations are in “athal_genes.gtf”. Use default parameters unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de720fd6-7dec-4263-9d4b-986805e26696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mDay16.fastq\u001b[0m  \u001b[01;32mDay8.fastq\u001b[0m  \u001b[01;32mWSL_commands.ipynb\u001b[0m  \u001b[01;32mathal_chr.fa\u001b[0m  \u001b[01;32mathal_genes.gtf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# These are the files we need, you can download them to your folder. Let view them in my folder:\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b033b0fa-635f-4324-a4ce-e014a7b16755",
   "metadata": {},
   "source": [
    "# Steps we will do:\n",
    "1. Index reference genome file using bowtie2-build\n",
    "2. Align RNA-seq reads (fastq) with indexed reference genome using tophat. (fastq -> BAM)\n",
    "3. Assemble aligned reads into genes and transcripts using cufflinks. (BAM -> transcripts.gtf)\n",
    "4. Use cuffcompare to compare the assembled transcripts against a set of reference gene annotations, exon-by-exon, to determine which genes and transcripts in the sample are known, and which ones are likely novel.\n",
    "5. Merge transcripts from 2 experimental conditions (Day 8 and Day 16) using cuffmerge. (gtf -> gtf)\n",
    "6. Differential Expression with cuffdiff to compare expression levels between Day8 and Day16: run cuffdiff with the ‘merged.gtf’ file as reference annotation, taking as input the two alignment files. (BAM files generated by tophat -> diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62832eb9-d623-4683-844c-5cf7e12949a5",
   "metadata": {},
   "source": [
    "## Step 1: Index reference genome file “athal_chr.fa” with bowtie2-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398d7c7d-00e5-48b2-a4ba-8858d5d2c59a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"athal.*.bt2\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 4 (one in 16)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Max bucket size: default\n",
      "  Max bucket size, sqrt multiplier: default\n",
      "  Max bucket size, len divisor: 4\n",
      "  Difference-cover sample period: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  athal.fa\n",
      "Building a SMALL index\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 125000\n",
      "Using parameters --bmax 93750 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 93750 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 6; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:01\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 71427.7 (target: 93749)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 23503\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 23504\n",
      "Getting block 2 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 88580\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 88581\n",
      "Getting block 3 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 45388\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 45389\n",
      "Getting block 4 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 88840\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 88841\n",
      "Getting block 5 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 86205\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 86206\n",
      "Getting block 6 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 89818\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 89819\n",
      "Getting block 7 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 77660\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 77661\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 163659\n",
      "fchr[G]: 250818\n",
      "fchr[T]: 337838\n",
      "fchr[$]: 500000\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4361256 bytes to primary EBWT file: athal.1.bt2\n",
      "Wrote 125008 bytes to secondary EBWT file: athal.2.bt2\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 500000\n",
      "    bwtLen: 500001\n",
      "    sz: 125000\n",
      "    bwtSz: 125001\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 31251\n",
      "    offsSz: 125004\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 48\n",
      "    sideBwtLen: 192\n",
      "    numSides: 2605\n",
      "    numLines: 2605\n",
      "    ebwtTotLen: 166720\n",
      "    ebwtTotSz: 166720\n",
      "    color: 0\n",
      "    reverse: 0\n",
      "Total time for call to driver() for forward index: 00:00:01\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "  Time to reverse reference sequence: 00:00:00\n",
      "bmax according to bmaxDivN setting: 125000\n",
      "Using parameters --bmax 93750 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 93750 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:01\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 7; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 0; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 71427.7 (target: 93749)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 77170\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 77171\n",
      "Getting block 2 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 68759\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 68760\n",
      "Getting block 3 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 91921\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 91922\n",
      "Getting block 4 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 31442\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 31443\n",
      "Getting block 5 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 70502\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 70503\n",
      "Getting block 6 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 74624\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 74625\n",
      "Getting block 7 of 7\n",
      "  Reserving size (93750) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 85576\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 85577\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 163659\n",
      "fchr[G]: 250818\n",
      "fchr[T]: 337838\n",
      "fchr[$]: 500000\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4361256 bytes to primary EBWT file: athal.rev.1.bt2\n",
      "Wrote 125008 bytes to secondary EBWT file: athal.rev.2.bt2\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 500000\n",
      "    bwtLen: 500001\n",
      "    sz: 125000\n",
      "    bwtSz: 125001\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 31251\n",
      "    offsSz: 125004\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 48\n",
      "    sideBwtLen: 192\n",
      "    numSides: 2605\n",
      "    numLines: 2605\n",
      "    ebwtTotLen: 166720\n",
      "    ebwtTotSz: 166720\n",
      "    color: 0\n",
      "    reverse: 1\n",
      "Total time for backward call to driver() for mirror index: 00:00:02\n"
     ]
    }
   ],
   "source": [
    "# Create a directory (dir) name athal. Copy athal_chr.fa to this dir and rename it to athal.fa\n",
    "mkdir athal # now your_folder has a new folder named \"athal\"\n",
    "cp athal_chr.fa athal/athal.fa\n",
    "# go to athal folder\n",
    "cd athal\n",
    "# Create a bowtie index of the genome using bowtie2-build, with the prefix ‘athal’. This generates 6 .bt2 files into the athal directory we just created\n",
    "bowtie2-build athal.fa athal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712caf2f-d7e2-4bcd-93a9-7b3518199415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mathal.1.bt2\u001b[0m  \u001b[01;32mathal.3.bt2\u001b[0m  \u001b[01;32mathal.fa\u001b[0m         \u001b[01;32mathal.rev.2.bt2\u001b[0m\n",
      "\u001b[01;32mathal.2.bt2\u001b[0m  \u001b[01;32mathal.4.bt2\u001b[0m  \u001b[01;32mathal.rev.1.bt2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 6 indexes files (.bt2) generated by bowtie2\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3010ae3d-41ef-4670-95ba-827e8e9bfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mDay16.fastq\u001b[0m  \u001b[01;32mWSL_commands.ipynb\u001b[0m  \u001b[01;32mathal_chr.fa\u001b[0m\n",
      "\u001b[01;32mDay8.fastq\u001b[0m   \u001b[34;42mathal\u001b[0m               \u001b[01;32mathal_genes.gtf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# go up 1 directory to your_folder\n",
    "cd ..\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940719b-bb66-4f37-8404-7c9decc7a812",
   "metadata": {},
   "source": [
    "## Step 2: Align the RNA-seq data with indexed genome using TopHat\n",
    "\n",
    "-p 8: Use 8 threads (you can adjust this depending on the number of cores you have available).\n",
    "\n",
    "-o Tophat/Day8: the output directories/folders where the results for each sample will be saved.\n",
    "\n",
    "athal/athal: the 1st athal is the folder, the 2nd athal is the prefix for the Bowtie2 index we just created.\n",
    "\n",
    "Day8.fastq is the RNA-seq read to be aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e805c7-0480-414d-a103-85def7d236b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-04-22 16:17:21] Beginning TopHat run (v2.0.14)\n",
      "-----------------------------------------------\n",
      "[2025-04-22 16:17:21] Checking for Bowtie\n",
      "\t\t  Bowtie version:\t 2.2.5.0\n",
      "[2025-04-22 16:17:21] Checking for Bowtie index files (genome)..\n",
      "[2025-04-22 16:17:21] Checking for reference FASTA file\n",
      "[2025-04-22 16:17:21] Generating SAM header for athal/athal\n",
      "[2025-04-22 16:17:21] Preparing reads\n",
      "\t left reads: min. length=50, max. length=50, 63573 kept reads (0 discarded)\n",
      "[2025-04-22 16:17:44] Mapping left_kept_reads to genome athal with Bowtie2 \n",
      "[2025-04-22 16:17:47] Mapping left_kept_reads_seg1 to genome athal with Bowtie2 (1/2)\n",
      "[2025-04-22 16:17:48] Mapping left_kept_reads_seg2 to genome athal with Bowtie2 (2/2)\n",
      "[2025-04-22 16:17:49] Searching for junctions via segment mapping\n",
      "\tCoverage-search algorithm is turned on, making this step very slow\n",
      "\tPlease try running TopHat again with the option (--no-coverage-search) if this step takes too much time or memory.\n",
      "[2025-04-22 16:17:50] Retrieving sequences for splices\n",
      "[2025-04-22 16:17:51] Indexing splices\n",
      "Building a SMALL index\n",
      "[2025-04-22 16:17:53] Mapping left_kept_reads_seg1 to genome segment_juncs with Bowtie2 (1/2)\n",
      "[2025-04-22 16:17:54] Mapping left_kept_reads_seg2 to genome segment_juncs with Bowtie2 (2/2)\n",
      "[2025-04-22 16:17:54] Joining segment hits\n",
      "[2025-04-22 16:17:56] Reporting output tracks\n",
      "-----------------------------------------------\n",
      "[2025-04-22 16:18:03] A summary of the alignment counts can be found in Tophat/Day8/align_summary.txt\n",
      "[2025-04-22 16:18:03] Run complete: 00:00:42 elapsed\n",
      "\n",
      "[2025-04-22 16:18:03] Beginning TopHat run (v2.0.14)\n",
      "-----------------------------------------------\n",
      "[2025-04-22 16:18:03] Checking for Bowtie\n",
      "\t\t  Bowtie version:\t 2.2.5.0\n",
      "[2025-04-22 16:18:03] Checking for Bowtie index files (genome)..\n",
      "[2025-04-22 16:18:03] Checking for reference FASTA file\n",
      "[2025-04-22 16:18:03] Generating SAM header for athal/athal\n",
      "[2025-04-22 16:18:04] Preparing reads\n",
      "\t left reads: min. length=50, max. length=50, 57985 kept reads (0 discarded)\n",
      "[2025-04-22 16:18:17] Mapping left_kept_reads to genome athal with Bowtie2 \n",
      "[2025-04-22 16:18:20] Mapping left_kept_reads_seg1 to genome athal with Bowtie2 (1/2)\n",
      "[2025-04-22 16:18:21] Mapping left_kept_reads_seg2 to genome athal with Bowtie2 (2/2)\n",
      "[2025-04-22 16:18:21] Searching for junctions via segment mapping\n",
      "\tCoverage-search algorithm is turned on, making this step very slow\n",
      "\tPlease try running TopHat again with the option (--no-coverage-search) if this step takes too much time or memory.\n",
      "[2025-04-22 16:18:23] Retrieving sequences for splices\n",
      "[2025-04-22 16:18:24] Indexing splices\n",
      "Building a SMALL index\n",
      "[2025-04-22 16:18:26] Mapping left_kept_reads_seg1 to genome segment_juncs with Bowtie2 (1/2)\n",
      "[2025-04-22 16:18:26] Mapping left_kept_reads_seg2 to genome segment_juncs with Bowtie2 (2/2)\n",
      "[2025-04-22 16:18:28] Joining segment hits\n",
      "[2025-04-22 16:18:30] Reporting output tracks\n",
      "-----------------------------------------------\n",
      "[2025-04-22 16:18:35] A summary of the alignment counts can be found in Tophat/Day16/align_summary.txt\n",
      "[2025-04-22 16:18:35] Run complete: 00:00:31 elapsed\n"
     ]
    }
   ],
   "source": [
    "mkdir Tophat\n",
    "mkdir Tophat/Day8\n",
    "mkdir Tophat/Day16\n",
    "tophat -p 8 -o Tophat/Day8 athal/athal Day8.fastq\n",
    "tophat -p 8 -o Tophat/Day16 athal/athal Day16.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ae24b-97d6-47f7-980c-188c0c0dca72",
   "metadata": {},
   "source": [
    "### Question 1: How many alignments were produced for the ‘Day8’  RNA-seq data set? \n",
    "Info is in accepted_hits.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1c5015-79d9-4584-b50d-6b3ddaafa820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNAME\tFLAG\tRNAME\tPOS\tMAPQ\tCIGAR\tRNEXT\tPNEXT\tTLEN\tSEQ\tQUAL\n",
      "SRR1660397.18502384\t16\t4\t103\t50\t3M1I46M\t*\t0\t0\tCCATTCAGGACATTCTGGTGGTGGACTCGGAGGCATGATAGCAGGTGCAG\tJIIHGJJIGHJIIIIIJJIGHCIGFIIJIJJJJJJJJHHHHHFFFFFCC@\tAS:i:-8\tXN:i:0\tXM:i:0\tXO:i:1\tXG:i:1\tNM:i:1\tMD:Z:49\tYT:Z:UU\tNH:i:1\n",
      "SRR1660397.9998980\t0\t4\t105\t50\t50M\t*\t0\t0\tTTCAGGACATTCTGGTGGTGGACTCGGAGGCATGATAGCAGGTGCAGCTG\t@@CFFEDDFFHHHBG<CF<CFGHDHIIFGB=EHBDBDA?DE9DGIEFI@G\tAS:i:-5\tXN:i:0\tXM:i:1\tXO:i:0\tXG:i:0\tNM:i:1\tMD:Z:0A49\tYT:Z:UU\tNH:i:1\n"
     ]
    }
   ],
   "source": [
    "# To print Field Descriptions and view the first 2 alignments in BAM file\n",
    "echo -e \"QNAME\\tFLAG\\tRNAME\\tPOS\\tMAPQ\\tCIGAR\\tRNEXT\\tPNEXT\\tTLEN\\tSEQ\\tQUAL\" # print out Field Descriptions manually\n",
    "samtools view Tophat/Day8/accepted_hits.bam | head -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9a11baf-b5b9-41b7-a209-594ee06ab471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63845\n"
     ]
    }
   ],
   "source": [
    "# To count alingments in BAM file\n",
    "samtools view -c Tophat/Day8/accepted_hits.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3018c83-8697-4cc6-a739-2a72002bf32e",
   "metadata": {},
   "source": [
    "### Q2: How many reads were mapped in ‘Day8’ RNA-seq data set?\n",
    "Info is in align_summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc10f884-828c-45ac-a863-ca00306a45cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reads:\n",
      "          Input     :     63573\n",
      "           Mapped   :     63489 (99.9% of input)\n",
      "            of these:       356 ( 0.6%) have multiple alignments (0 have >20)\n",
      "99.9% overall read mapping rate.\n"
     ]
    }
   ],
   "source": [
    "# Display the content of align_summary.txt in the terminal\n",
    "cat Tophat/Day8/align_summary.txt\n",
    "# the number of mapped reads is 63489"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f280e14-a540-4823-a496-136b9a632317",
   "metadata": {},
   "source": [
    "### Q3: How many spliced alignments were reported for ‘Day8’ RNA-seq data set?\n",
    "A spliced alignment would be marked with ‘N’ in the CIGAR field (column 6) of accepted_hits.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee03dc4d-8bf0-45a0-9a38-dc02849d7cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8596\n",
      "SRR1660397.1102913\t0\t4\t1266\t3\t49M579N1M\t*\t0\t0\tCACACGCTTTTTCATTTCAATCTTCTTCTTCTACTCTTAAGTATCTCAGG\t@@@DDDADFFHGDHGIIGIIJGIIHIIJIJGCABHHIIGIIJIJJJIGEG\tAS:i:0\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:50\tYT:Z:UU\tXS:A:+\tNH:i:2\tHI:i:1\n"
     ]
    }
   ],
   "source": [
    "samtools view Tophat/Day8/accepted_hits.bam | cut -f6 | grep -c 'N'\n",
    "# to view an example spliced alignment\n",
    "samtools view Tophat/Day8/accepted_hits.bam | awk '$6 ~ /N/' | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c486536-a217-4891-be39-9cf2a6833710",
   "metadata": {},
   "source": [
    "## Step 3: assemble the aligned RNA-seq reads into genes and transcripts using cufflinks. \n",
    "Use the labels ‘Day8’ and ‘Day16’, respectively, when creating identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5823578-2153-4c76-95f8-7141017f9a72",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n",
      "[17:06:59] Inspecting reads and determining fragment length distribution.\n",
      "> Processed 321 loci.                          [*************************] 100%\n",
      "> Map Properties:\n",
      ">\tNormalized Map Mass: 63489.00\n",
      ">\tRaw Map Mass: 63489.00\n",
      ">\tFragment Length Distribution: Truncated Gaussian (default)\n",
      ">\t              Default Mean: 200\n",
      ">\t           Default Std Dev: 80\n",
      "[17:07:00] Assembling transcripts and estimating abundances.\n",
      "> Processed 327 loci.                          [*************************] 100%\n",
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n",
      "[17:07:06] Inspecting reads and determining fragment length distribution.\n",
      "> Processed 139 loci.                          [*************************] 100%\n",
      "> Map Properties:\n",
      ">\tNormalized Map Mass: 57951.00\n",
      ">\tRaw Map Mass: 57951.00\n",
      ">\tFragment Length Distribution: Truncated Gaussian (default)\n",
      ">\t              Default Mean: 200\n",
      ">\t           Default Std Dev: 80\n",
      "[17:07:08] Assembling transcripts and estimating abundances.\n",
      "> Processed 161 loci.                          [*************************] 100%\n"
     ]
    }
   ],
   "source": [
    "mkdir Cufflinks\n",
    "mkdir Cufflinks/Day8\n",
    "mkdir Cufflinks/Day16\n",
    "cufflinks -o Cufflinks/Day8 -L Day8 Tophat/Day8/accepted_hits.bam\n",
    "cufflinks -o Cufflinks/Day16 -L Day16 Tophat/Day16/accepted_hits.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba3ff8-295d-4257-af77-d882b7dccef6",
   "metadata": {},
   "source": [
    "### Q4: How many genes were generated by cufflinks for Day8?\n",
    "cufflinks generates ‘transcripts.gtf’ containing the assembled transcripts, as well as files ‘*.fpkm_tracking’ containing expression (FPKM) estimates for genes and transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ff5dd7-5f14-48c5-8fd3-d650f0549b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom\tsource\tfeature\tstart\tend\tscore\tstrand\tframe\tattribute\n",
      "4\tCufflinks\ttranscript\t103\t721\t1000\t.\t.\tgene_id \"Day8.1\"; transcript_id \"Day8.1.1\"; FPKM \"120347.2406938536\"; frac \"1.000000\"; conf_lo \"116072.911057\"; conf_hi \"124621.570330\"; cov \"382.036298\";\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "# To view the first line of GTF file\n",
    "echo -e \"chrom\\tsource\\tfeature\\tstart\\tend\\tscore\\tstrand\\tframe\\tattribute\" # print field description\n",
    "head -n 1 Cufflinks/Day8/transcripts.gtf\n",
    "# extract column 9 which contain gene_ID | extract gene_ID, ie, \"Day8.1\"; | sort and eliminate duplicate | count how many gene_IDs/genes in transcripts.gtf file\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f2 | sort -u | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996ce5a-e529-487b-abbf-0098160e3dcd",
   "metadata": {},
   "source": [
    "### Q5: How many transcripts were reported for Day8? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a556a2b1-0341-473b-bb80-c42586dc0193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "# extract column 9 which contain transcript_ID | extract transcript_ID, ie, \"Day8.1.1\"; | sort and eliminate duplicate | count how many transcript_IDs/transcripts in transcripts.gtf file\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f4 | sort -u | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a51829-c1cd-4540-b310-72c5925acacd",
   "metadata": {},
   "source": [
    "### Q6: How many single transcript genes were produced for Day8? \n",
    "Each gene can have one or more transcripts. We first create a listing of (column 1 as gene, column 2 as transcript) pairs by \"cut -d ' ' -f2,4\" and use it to determine the number of transcripts for each gene. For instance, a gene with a single transcript would appear only 1 time in column 1, a gene with 2 transcripts 2 times, etc. We calculate the number of occurrences in column 1 for each gene using ‘uniq -c’, and then select those that have count 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d2b66f-90e3-4920-957a-9e8223af99fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Day8.1\"; \"Day8.1.1\";\n",
      "\"Day8.10\"; \"Day8.10.1\";\n",
      "      1 \"Day8.1\";\n",
      "      1 \"Day8.10\";\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# visualize the outcome of each command\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f2,4 | sort -u | head -n 2\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f2,4 | sort -u | cut -d ' ' -f1 | sort | uniq -c | head -n 2\n",
    "# count genes with only 1 transcript\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f2,4 | sort -u | cut -d ' ' -f1 | sort | uniq -c | grep -c \" 1 \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bcb2a-081e-4bb1-bfb9-840d15a0592b",
   "metadata": {},
   "source": [
    "### Q7: How many single-exon transcripts were in the Day8 set?\n",
    "Each transcript is represented in the GTF file with one ‘transcript’ (column 3) line and one or several ‘exon’ (column 3) lines. Therefore, a single-exon transcript would appear listed on exactly 2 lines: 1 line for transcript, 1 line for exon. Note that these 2 lines have the same transcript_id in column 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b32d699-2547-4dc6-98a1-2d5891ee47ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 \"Day8.1.1\";\n",
      "119\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "# visualize a transcript with single-exon\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f4 | sort | uniq -c | grep \" 2 \" | head -n 1\n",
    "# count transcript with only 1 exon\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f4 | sort | uniq -c | grep -c \" 2 \"\n",
    "# count transcript wit multiple exon by command line\n",
    "cut -f9 Cufflinks/Day8/transcripts.gtf | cut -d ' ' -f4 | sort | uniq -c | awk '$1 > 2' | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7c74a-f9d1-411d-85d3-849ccd752e38",
   "metadata": {},
   "source": [
    "## Step 4: cuffcompare \n",
    "cuffcompare compares the assembled transcripts against a set of reference gene annotations provided by the user, exon-by-exon, to determine which genes and transcripts in the sample are known, and which ones are likely novel. \n",
    "In the end, it assigns each predicted (cufflinks) transcript a ‘class’ code depending on how it relates to a reference transcript, for example: it is the same as a reference transcript (‘=’), it is only a portion of one (‘c’), a new splice variant of a reference gene (‘j’), etc. \n",
    "Run cuffcompare against the provided annotation (‘-r’) and with the option ‘-R’ to exclude from statistics genes that do not appear to be represented in the sample.\n",
    "These will create the files ‘day*.combined.gtf’ combining the reference and predicted annotations, ‘day*.transcripts.gtf.tmap’ containing a mapping between the assembled transcripts and the reference genes and transcripts, as well as other derived files, in the corresponding directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62cd1ef6-eb67-4b88-88ac-442163dde76a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuffcompare v2.2.1 (4237)\n",
      "-----------------------------\n",
      "Usage:\n",
      "cuffcompare [-r <reference_mrna.gtf>] [-R] [-T] [-V] [-s <seq_path>] \n",
      "    [-o <outprefix>] [-p <cprefix>] \n",
      "    {-i <input_gtf_list> | <input1.gtf> [<input2.gtf> .. <inputN.gtf>]}\n",
      "\n",
      " Cuffcompare provides classification, reference annotation mapping and various\n",
      " statistics for Cufflinks transfrags.\n",
      " Cuffcompare clusters and tracks transfrags across multiple samples, writing\n",
      " matching transcripts (intron chains) into <outprefix>.tracking, and a GTF\n",
      " file <outprefix>.combined.gtf containing a nonredundant set of transcripts \n",
      " across all input files (with a single representative transfrag chosen\n",
      " for each clique of matching transfrags across samples).\n",
      "\n",
      "Options:\n",
      "-i provide a text file with a list of Cufflinks GTF files to process instead\n",
      "   of expecting them as command line arguments (useful when a large number\n",
      "   of GTF files should be processed)\n",
      "\n",
      "-r a set of known mRNAs to use as a reference for assessing \n",
      "   the accuracy of mRNAs or gene models given in <input.gtf>\n",
      "\n",
      "-R for -r option, consider only the reference transcripts that\n",
      "   overlap any of the input transfrags (Sn correction)\n",
      "-Q for -r option, consider only the input transcripts that\n",
      "   overlap any of the reference transcripts (Sp correction);\n",
      "   (Warning: this will discard all \"novel\" loci!)\n",
      "-M discard (ignore) single-exon transfrags and reference transcripts\n",
      "-N discard (ignore) single-exon reference transcripts\n",
      "\n",
      "-s <seq_path> can be a multi-fasta file with all the genomic sequences or \n",
      "   a directory containing multiple single-fasta files (one file per contig);\n",
      "   lower case bases will be used to classify input transcripts as repeats\n",
      "\n",
      "-e max. distance (range) allowed from free ends of terminal exons of reference\n",
      "   transcripts when assessing exon accuracy (100)\n",
      "-d max. distance (range) for grouping transcript start sites (100)\n",
      "-p the name prefix to use for consensus transcripts in the \n",
      "   <outprefix>.combined.gtf file (default: 'TCONS')\n",
      "-C include the \"contained\" transcripts in the .combined.gtf file\n",
      "-F do not discard intron-redundant transfrags if they share the 5' end\n",
      "   (if they differ only at the 3' end))\n",
      "-G generic GFF input file(s): do not assume Cufflinks GTF, do not\n",
      "   discard any intron-redundant transfrags)\n",
      "-T do not generate .tmap and .refmap files for each input file\n",
      "-V verbose processing mode (showing all GFF parsing warnings)\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cuffcompare # see how to use cuffcompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e333f87d-b2ea-4036-a397-d866bf32b318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n"
     ]
    }
   ],
   "source": [
    "mkdir -p cuffcompare/Day8 # -p prevent error message when cuffcompare/Day8 already exist\n",
    "cuffcompare -r athal_genes.gtf -R -o cuffcompare/Day8/day8 Cufflinks/Day8/transcripts.gtf\n",
    "# -o cuffcompare/Day8/day8 will generate cuffcompare/Day8/day8.combined.gtf and other files. Note that this command output day8.transcripts.gtf.tmap in Cufflinks/Day8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84477b19-1635-440b-a1de-f35463ef885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n"
     ]
    }
   ],
   "source": [
    "mkdir -p cuffcompare/Day16\n",
    "cuffcompare -r athal_genes.gtf -R -o cuffcompare/Day16/day16 Cufflinks/Day16/transcripts.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b846a6-bc3d-491d-bb5f-ba8827a4047e",
   "metadata": {},
   "source": [
    "### Q8: How many cufflinks transcripts fully reconstruct annotation transcripts in Day8?\n",
    "transcripts fully reconstruct annotation transcripts is indicated by the ‘class’ code \"=\" in column 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5258bf5-5e04-49d2-af6e-b56d9ded2a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_gene_id\tref_id\tclass_code\tcuff_gene_id\tcuff_id\tFMI\tFPKM\tFPKM_conf_lo\tFPKM_conf_hi\tcov\tlen\tmajor_iso_id\tref_match_len\n",
      "AT4G19200\tAT4G19200.1\t=\tDay8.1\tDay8.1.1\t100\t120347.240694\t116072.911057\t124621.570330\t382.036298\t619\tDay8.1.1\t613\n"
     ]
    }
   ],
   "source": [
    "# to view the first 2 lines of .tmap file\n",
    "head -n 2 Cufflinks/Day8/day8.transcripts.gtf.tmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f217f906-09e8-4b70-951b-6c5ffbb614ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16 =\n",
      "    133 c\n",
      "      1 class_code\n",
      "      7 e\n",
      "      4 i\n",
      "     14 j\n",
      "     15 o\n",
      "      3 p\n"
     ]
    }
   ],
   "source": [
    "cut -f3 Cufflinks/Day8/day8.transcripts.gtf.tmap | sort | uniq -c \n",
    "# the answer is 16\n",
    "# there are 133 cufflinks transcripts that are partial reconstructions of reference transcripts, indicated by class_code \"c\"\n",
    "# there are 4 cufflinks transcripts that were formed in the introns of reference genes, indicated by class_code \"i\"\n",
    "# there are 14 cufflinks transcripts that are novel splice variants of reference genes, indicated by class_code \"j\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac233c-813a-43f6-a30a-c058a5c94700",
   "metadata": {},
   "source": [
    "### Q9: How many splice variants does the gene AT4G20240 have in the Day8 sample? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f86d0ca-f6ae-4968-8e00-2397294e3ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;31m\u001b[KAT4G20240\u001b[m\u001b[K\t\u001b[01;31m\u001b[KAT4G20240\u001b[m\u001b[K.1\tj\tDay8.159\tDay8.159.1\t100\t6112.378433\t5517.096482\t6707.660384\t19.403440\t1294\tDay8.159.1\t1608\n",
      "\u001b[01;31m\u001b[KAT4G20240\u001b[m\u001b[K\t\u001b[01;31m\u001b[KAT4G20240\u001b[m\u001b[K.1\to\tDay8.160\tDay8.160.1\t100\t4289.867816\t3045.166614\t5534.569017\t13.617971\t380\tDay8.160.1\t1608\n"
     ]
    }
   ],
   "source": [
    "grep \"AT4G20240\" Cufflinks/Day8/day8.transcripts.gtf.tmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65a14009-f9f5-411c-a37d-a5bffff35db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "grep \"AT4G20240\" Cufflinks/Day8/day8.transcripts.gtf.tmap | wc -l # the answer is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e26ba-e2f6-41c2-8939-542f588ecae9",
   "metadata": {},
   "source": [
    "# Step 5: Merge transcripts using cuffmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d23b1475-d4e1-406f-adc1-f75041a02af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, prepare a text file (e.g., assemblies.txt) that lists the paths to both transcripts.gtf files:\n",
    "echo Cufflinks/Day8/transcripts.gtf > assemblies.txt\n",
    "echo Cufflinks/Day16/transcripts.gtf >> assemblies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e34543c8-6f27-44d1-a5d3-65535e91816d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Tue Apr 22 18:40:13 2025] Beginning transcriptome assembly merge\n",
      "-------------------------------------------\n",
      "\n",
      "[Tue Apr 22 18:40:13 2025] Preparing output location ./merged_asm/\n",
      "[Tue Apr 22 18:40:13 2025] Converting GTF files to SAM\n",
      "[18:40:13] Loading reference annotation.\n",
      "[18:40:13] Loading reference annotation.\n",
      "[Tue Apr 22 18:40:13 2025] Quantitating transcripts\n",
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n",
      "Command line:\n",
      "cufflinks -o ./merged_asm/ -F 0.05 -g athal_genes.gtf -q --overhang-tolerance 200 --library-type=transfrags -A 0.0 --min-frags-per-transfrag 0 --no-5-extend -p 1 ./merged_asm/tmp/mergeSam_fileEZpXzc \n",
      "[bam_header_read] EOF marker is absent. The input is probably truncated.\n",
      "[bam_header_read] invalid BAM binary header (this is not a BAM file).\n",
      "File ./merged_asm/tmp/mergeSam_fileEZpXzc doesn't appear to be a valid BAM file, trying SAM...\n",
      "[18:40:13] Loading reference annotation.\n",
      "[18:40:13] Inspecting reads and determining fragment length distribution.\n",
      "Processed 119 loci.                         \n",
      "> Map Properties:\n",
      ">\tNormalized Map Mass: 284.00\n",
      ">\tRaw Map Mass: 284.00\n",
      ">\tFragment Length Distribution: Truncated Gaussian (default)\n",
      ">\t              Default Mean: 200\n",
      ">\t           Default Std Dev: 80\n",
      "[18:40:14] Assembling transcripts and estimating abundances.\n",
      "Processed 119 loci.                         \n",
      "[Tue Apr 22 18:40:15 2025] Comparing against reference file athal_genes.gtf\n",
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n",
      "[Tue Apr 22 18:40:16 2025] Comparing against reference file athal_genes.gtf\n",
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n"
     ]
    }
   ],
   "source": [
    "cuffmerge -g athal_genes.gtf assemblies.txt # this will create a directory ‘merged_asm’ containing the file ‘merged.gtf’."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae6b3e-2bca-4e47-b385-c08e41db2dbf",
   "metadata": {},
   "source": [
    "### Q10: How many genes (loci) were reported in the merged.gtf file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0ef5596-2162-41b2-9c5f-d7aa666813ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom\tsource\tfeature\tstart\tend\tscore\tstrand\tframe\tattribute\n",
      "4\tCufflinks\texon\t110\t722\t.\t+\t.\tgene_id \"XLOC_000001\"; transcript_id \"TCONS_00000001\"; exon_number \"1\"; gene_name \"AT4G19200\"; oId \"AT4G19200.1\"; nearest_ref \"AT4G19200.1\"; class_code \"=\"; tss_id \"TSS1\";\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "echo -e \"chrom\\tsource\\tfeature\\tstart\\tend\\tscore\\tstrand\\tframe\\tattribute\" # print field description\n",
    "head -n 1 merged_asm/merged.gtf\n",
    "cut -f9 merged_asm/merged.gtf | cut -d ' ' -f2 | sort -u | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45dc95-d720-438d-9bb2-6a72073c6ebb",
   "metadata": {},
   "source": [
    "# Step 6: Differential Expression with cuffdiff to compare expression levels between Day8 and Day16\n",
    "run cuffdiff with the ‘merged.gtf’ file as reference annotation, taking as input the two alignment files and directing the output to the directory Cuffdiff (‘-o’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8247fa29-35c3-409e-a101-db20243ef347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not connect to update server to verify current version. Please check at the Cufflinks website (http://cufflinks.cbcb.umd.edu).\n",
      "[18:47:19] Loading reference annotation.\n",
      "Warning: No conditions are replicated, switching to 'blind' dispersion method\n",
      "[18:47:19] Inspecting maps and determining fragment length distributions.\n",
      "[18:47:20] Modeling fragment count overdispersion.\n",
      "> Map Properties:\n",
      ">\tNormalized Map Mass: 61354.33\n",
      ">\tRaw Map Mass: 62678.00\n",
      ">\tFragment Length Distribution: Truncated Gaussian (default)\n",
      ">\t              Default Mean: 200\n",
      ">\t           Default Std Dev: 80\n",
      "> Map Properties:\n",
      ">\tNormalized Map Mass: 61354.33\n",
      ">\tRaw Map Mass: 56432.50\n",
      ">\tFragment Length Distribution: Truncated Gaussian (default)\n",
      ">\t              Default Mean: 200\n",
      ">\t           Default Std Dev: 80\n",
      "[18:47:53] Calculating preliminary abundance estimates\n",
      "[18:47:53] Testing for differential expression and regulation in locus.\n",
      "> Processed 116 loci.                          [*************************] 100%\n",
      "Performed 111 isoform-level transcription difference tests\n",
      "Performed 83 tss-level transcription difference tests\n",
      "Performed 66 gene-level transcription difference tests\n",
      "Performed 0 CDS-level transcription difference tests\n",
      "Performed 0 splicing tests\n",
      "Performed 0 promoter preference tests\n",
      "Performing 0 relative CDS output tests\n",
      "Writing isoform-level FPKM tracking\n",
      "Writing TSS group-level FPKM tracking\n",
      "Writing gene-level FPKM tracking\n",
      "Writing CDS-level FPKM tracking\n",
      "Writing isoform-level count tracking\n",
      "Writing TSS group-level count tracking\n",
      "Writing gene-level count tracking\n",
      "Writing CDS-level count tracking\n",
      "Writing isoform-level read group tracking\n",
      "Writing TSS group-level read group tracking\n",
      "Writing gene-level read group tracking\n",
      "Writing CDS-level read group tracking\n",
      "Writing read group info\n",
      "Writing run info\n"
     ]
    }
   ],
   "source": [
    "mkdir Cuffdiff\n",
    "cuffdiff -o Cuffdiff merged_asm/merged.gtf Tophat/Day8/accepted_hits.bam Tophat/Day16/accepted_hits.bam\n",
    "# This will create the file ‘gene_exp.diff’ containing test scores and results for the gene-level differential expression analysis, \n",
    "# also generate other ‘*.diff’ files, as well as tracking files for genes, transcripts, splicing, CDS, TSS, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954470b-a094-4261-bc32-89c543166668",
   "metadata": {},
   "source": [
    "### Q11: How many genes total were included in the gene expression report from cuffdiff?\n",
    "count the number of lines in the ‘gene_exp.diff’ file and subtract 1 (the header):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36634965-013e-4272-af35-82eb8907c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id\tgene_id\tgene\tlocus\tsample_1\tsample_2\tstatus\tvalue_1\tvalue_2\tlog2(fold_change)\ttest_stat\tp_value\tq_value\tsignificant\n",
      "XLOC_000001\tXLOC_000001\tAT4G19200\t4:109-722\tq1\tq2\tOK\t152925\t11993.6\t-3.67249\t-2.98827\t0.0111\t0.14652\tno\n",
      "130 Cuffdiff/gene_exp.diff\n"
     ]
    }
   ],
   "source": [
    "head -n 2 Cuffdiff/gene_exp.diff\n",
    "wc -l Cuffdiff/gene_exp.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d7247-3a64-4d6f-9b8e-776bb46feb6a",
   "metadata": {},
   "source": [
    "### Q12: How many genes were detected as differentially expressed?\n",
    "look at column 13 \"significant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9112d3ec-844d-4f2a-949b-bc6cf0c3321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "grep -c yes Cuffdiff/gene_exp.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af39dd-f8cd-444f-aeb2-f91d915a53c2",
   "metadata": {},
   "source": [
    "### Q13: How many transcripts were differentially expressed between the two samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8807bbbc-0e2c-43c0-8fd5-660e428ae35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "grep -c yes Cuffdiff/isoform_exp.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8152e4ff-a6dd-4b9e-bf89-b8a63a1efcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When done with your analysis, deactivate JK_tophit\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91ba27b0-f446-44d1-913c-11e14a1cc779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                 * /home/lam/miniconda3\n",
      "JK                     /home/lam/miniconda3/envs/JK\n",
      "JK_tophat              /home/lam/miniconda3/envs/JK_tophat\n",
      "centrifuge             /home/lam/miniconda3/envs/centrifuge\n",
      "kb                     /home/lam/miniconda3/envs/kb\n",
      "rnaseq                 /home/lam/miniconda3/envs/rnaseq\n",
      "rnaseq_py38            /home/lam/miniconda3/envs/rnaseq_py38\n",
      "sourmash               /home/lam/miniconda3/envs/sourmash\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To check that JK_tophat is deactivated\n",
    "conda info --envs # this lists all conda environments I've created\n",
    "# I should see a * in the line of base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3568df1-51cb-49a2-b2b4-87567b9f70bf",
   "metadata": {},
   "source": [
    "# Testing your knowledge\n",
    "You can try answering the above questions for the ‘Day16’  RNA-seq data set.\n",
    "Then try these additional questions:\n",
    "### Q1: How many reads were uniquely aligned in ‘Day8’ RNA-seq data set?\n",
    "### Q2: How many reads were left unmapped from ‘Day8’ RNA-seq data set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
